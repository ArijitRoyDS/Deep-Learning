{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cd5fe3",
   "metadata": {},
   "source": [
    "YOLO - You Only Look Once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb278450",
   "metadata": {},
   "source": [
    "COCO labels: https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b519a21",
   "metadata": {},
   "source": [
    "download yolov3.weights and yolov3.cfg files from \n",
    "\n",
    "https://github.com/AlexeyAB/darknet#how-to-evaluate-ap-of-yolov4-on-the-ms-coco-evaluation-server\n",
    "\n",
    "and save them in 'Data' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3c1f9",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # store the center position of the object\n",
    "        self.center_points = {}\n",
    "        # keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "        \n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "        \n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x+x+w)//2\n",
    "            cy = (y+y+h)//2\n",
    "            \n",
    "            # find out if the object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "                \n",
    "                if dist < 25:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x,y,w,h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "            # New object is detected, we assign the Id to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x,y,w,h, self.id_count])\n",
    "                self.id_count +=1\n",
    "        # Clean the dictionary by center points to remove IDs not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _,_,_,_, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "            \n",
    "        # Update dictionary with IDs not used - remove them\n",
    "        self_center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6443c18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "tracker = EuclideanDistTracker()\n",
    "cap = cv2.VideoCapture('Data/highway.mp4')\n",
    "\n",
    "# Object detecting from stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        # Extract region of interest (cropping the region of interest)\n",
    "        roi = frame[340:720, 500:800]\n",
    "\n",
    "        # Part1 - Object Detection\n",
    "        mask = object_detector.apply(roi)\n",
    "        _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "        contours,_ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        detections = []\n",
    "\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 100:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detections.append([x, y, w, h])\n",
    "\n",
    "        # Part2 - Object Tracking\n",
    "        boxes_ids = tracker.update(detections)\n",
    "        for box_id in boxes_ids:\n",
    "            x, y, w, h, id = box_id\n",
    "            cv2.putText(roi, str(id), (x, y -15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "            cv2.rectangle(roi, (x,y), (x+w, y+h),(0,255,0),3)\n",
    "        cv2.imshow(\"roi\", roi)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow(\"mask\", mask)\n",
    "\n",
    "        key = cv2.waitKey(30)\n",
    "        if key ==27:\n",
    "            break\n",
    "            \n",
    "except:\n",
    "    pass\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cddb70",
   "metadata": {},
   "source": [
    "# Count of vehicles in a video footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534aaf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the input video\n",
    "cap = cv2.VideoCapture('Data/bangkok2.mp4')\n",
    "\n",
    "# Get the video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec for the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "# Create the video writer\n",
    "out = cv2.VideoWriter('Data/output_traffic_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "# Load the YOLO model\n",
    "net = cv2.dnn.readNetFromDarknet('Data/yolov3.cfg', 'Data/yolov3.weights')\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Get the names of the output layers\n",
    "output_layers = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Initialize the list of tracked vehicles and their unique IDs\n",
    "tracked_vehicles = []\n",
    "vehicle_id = 0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize the frame for faster processing (optional)\n",
    "    resized_frame = cv2.resize(frame, None, fx=0.6, fy=0.6)\n",
    "    \n",
    "    # Perform object detection using YOLO\n",
    "    blob = cv2.dnn.blobFromImage(resized_frame, 0.00392, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_outputs = net.forward(output_layers)\n",
    "    \n",
    "    # Initialize lists for bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    # Process each output layer\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            if confidence > 0.5 and class_id in [2, 3, 5]:  # Class ID 2 represents vehicles in the COCO dataset\n",
    "                # Scale the bounding box coordinates to match the original image size\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                (center_x, center_y, box_width, box_height) = box.astype('int')\n",
    "                x = int(center_x - (box_width / 2))\n",
    "                y = int(center_y - (box_height / 2))\n",
    "                \n",
    "                # Add the bounding box, confidence, and class ID to the respective lists\n",
    "                boxes.append([x, y, int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    # Perform non-maximum suppression to eliminate redundant overlapping boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    # Initialize the list of detected vehicle centroids for this frame\n",
    "    centroids = []\n",
    "    \n",
    "    # Process each detected bounding box\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            \n",
    "            # Calculate the centroid of the bounding box\n",
    "            centroid_x = x + (w // 2)\n",
    "            centroid_y = y + (h // 2)\n",
    "            \n",
    "            # Add the centroid to the list\n",
    "            centroids.append((centroid_x, centroid_y))\n",
    "            \n",
    "            # Draw the bounding box and centroid on the frame\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.circle(frame, (centroid_x, centroid_y), 4, (0, 255, 255), -1)\n",
    "    \n",
    "    # Update the list of tracked vehicles\n",
    "    for centroid in centroids:\n",
    "        x, y = centroid\n",
    "        \n",
    "        # Check if the current centroid is close to an existing tracked vehicle\n",
    "        close_vehicle = False\n",
    "        for vehicle in tracked_vehicles:\n",
    "            distance = np.linalg.norm(np.array(centroid) - np.array(vehicle['centroid']))\n",
    "            if distance < 50:\n",
    "                close_vehicle = True\n",
    "                break\n",
    "        \n",
    "        # If not close to any existing vehicle, add it to the list with a new ID\n",
    "        if not close_vehicle:\n",
    "            tracked_vehicles.append({\n",
    "                'centroid': centroid,\n",
    "                'id': vehicle_id\n",
    "            })\n",
    "            vehicle_id += 1\n",
    "    \n",
    "    # Display the count of unique vehicles in real-time\n",
    "    cv2.putText(frame, f\"Vehicle Count: {len(tracked_vehicles)}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Write the frame with bounding boxes and count to the output video\n",
    "    out.write(frame)\n",
    "    \n",
    "    # Display the frame with bounding boxes and count\n",
    "    cv2.imshow('Vehicle Tracking', frame)\n",
    "    \n",
    "    # Check if the 'x' key is pressed to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and video writer\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894da9a",
   "metadata": {},
   "source": [
    "# Detect and label all objects on the road & save as csv file with Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53531878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Load the YOLO model\n",
    "net = cv2.dnn.readNetFromDarknet('Data/yolov3.cfg', 'Data/yolov3.weights')\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Load the classes\n",
    "with open('Data/coco.names', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('Data/adas2.mp4')\n",
    "\n",
    "# Get original video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Calculate new dimensions for 1080p resolution\n",
    "new_width = 1920  \n",
    "new_height = 1080  \n",
    "\n",
    "# Create video writer for resized video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "resized_video = cv2.VideoWriter('resized_traffic_video.mp4', fourcc, fps, (new_width, new_height))\n",
    "\n",
    "# Create CSV writer\n",
    "csv_file = open('object_detection_results.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Timestamp', 'Class', 'Confidence', 'X', 'Y', 'Width', 'Height'])\n",
    "\n",
    "# Set NMS parameters\n",
    "conf_threshold = 0.6\n",
    "nms_threshold = 0.25\n",
    "\n",
    "# Process each frame of the video\n",
    "frame_index = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize frame to 1080p\n",
    "    resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "    \n",
    "    # Detect objects in the resized frame\n",
    "    blob = cv2.dnn.blobFromImage(resized_frame, 0.00392, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward(output_layers)\n",
    "    \n",
    "    # Process each detection\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    \n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filter objects by class and confidence threshold\n",
    "            if confidence > conf_threshold and class_id in [i for i in range(80)]:\n",
    "                # Calculate object bounding box coordinates\n",
    "                center_x = int(obj[0] * new_width)\n",
    "                center_y = int(obj[1] * new_height)\n",
    "                width = int(obj[2] * new_width)\n",
    "                height = int(obj[3] * new_height)\n",
    "                x = int(center_x - width / 2)\n",
    "                y = int(center_y - height / 2)\n",
    "                \n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, width, height])\n",
    "    \n",
    "    # Apply NMS to eliminate redundant detections\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    \n",
    "    # Process the remaining detections after NMS\n",
    "    for i in indices:\n",
    "        class_id = class_ids[i]\n",
    "        confidence = confidences[i]\n",
    "        box = boxes[i]\n",
    "\n",
    "        # Unpack the box coordinates\n",
    "        x, y, width, height = box\n",
    "\n",
    "        # Write object information to CSV\n",
    "        csv_writer.writerow([frame_index / fps, classes[class_id], confidence, x, y, width, height])\n",
    "\n",
    "        # Draw object bounding box and label on the frame\n",
    "        cv2.rectangle(resized_frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "        cv2.putText(resized_frame, f'{classes[class_id]}: {confidence:.2f}', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "    # Write the resized frame to the resized video\n",
    "    resized_video.write(resized_frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Object Detection', resized_frame)\n",
    "    \n",
    "    # Break the loop if the 'x' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "    \n",
    "    frame_index += 1\n",
    "\n",
    "# Release the video capture, close CSV file, and close video writer\n",
    "cap.release()\n",
    "csv_file.close()\n",
    "resized_video.release()\n",
    "\n",
    "# Close OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c1bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2555d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41439e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
